# cdc

## 지속적 변화 수집 패턴 / 변경 데이터 캡처 수집 패턴

*

    ![image](https://user-images.githubusercontent.com/47103479/223735644-130c5577-6ae6-435d-abe7-b7566301793d.png)

    * https://airbyte.com/blog/change-data-capture-definition-methods-and-benefits
* 조직이 성숙해지면 일괄 수집을 넘어 변경 데이터 캡처(CDC, Change Data Capture) 패턴으로 이동합니다.
* 데이터베이스에 기록하는 모든 데이터의 변화를 관찰해 다른 시스템으로 데이터를 복제할 수 있는 형태로 추출하는 과정
* 짧은 지연 시간(몇 초 또는 몇 분)으로 대상에서 소스 업데이트가 필요한 지속적인 데이터 이동에 적용 가능합니다. CDC는 소스에서 모든 변경 이벤트(업데이트, 삭제, 삽입)를 캡처하고 대상에 업데이트를 적용합니다.
  * 테이블 변경은 행 변경(행 삽입, 행 업데이트, 행 삭제) 또는 스키마 변경(열 추가, 열 변경, 열 삭제).
* CDC는 여러 이기종 데이터 저장소(예: MySQL 및 ElasticSearch)를 동기화해야 하고 이중 쓰기 및 분산 트랜잭션과 같은 기존 기술에 존재하는 문제를 해결해야 하는 사용 사례에서 점점 인기를 얻고 있습니다. MySQL 및 PostgreSQL과 같은 데이터베이스에서 트랜잭션 로그는 CDC 이벤트의 소스입니다.
* CDC 수집 패턴 중에는 병합 단계를 거치지 않고 직접 이벤트를 사용할 수 있는 변형도 있습니다. 이 변형 패턴은 일반적으로 원시 CDC 이벤트가 비즈니스 특정 이벤트로 변환되는 시나리오에 적용됩니다.
* 이 접근 방식은 빠르게 이동하는 대용량 데이터에 적합하며, 널리 사용되고 가장 인기 있는 접근법 중 하나로 오류 없는 업데이트 추적 및 대규모 업데이트 병합을 보장하려면 소스 팀과 데이터 엔지니어링 팀 간의 운영 성숙도가 필요합니다.
* CDC는 새로운 데이터베이스 이벤트가 발생할 때 지속적으로 데이터를 이동 및 처리하여 실시간 또는 거의 실시간에 가까운 데이터 이동을 제공합니다. 시간에 민감한 결정이 내려지는 고속 데이터 환경에서 Change Data Capture는 지연 시간이 짧고 안정적이며 확장 가능한 데이터 복제를 달성하는 데 매우 적합하며 다운타임 없이 클라우드로 마이그레이션 하는 데에도 이상적입니다.
* CDC 수집 패턴
  *
    1. CDC 이벤트 생성
    2. CDC 어댑터는 소스 데이터베이스에 설치되고 구성됩니다. 이 어댑터는 사용자 지정 테이블에 대한 삽입, 업데이트, 삭제를 추적하기 위한 소스 데이터스토어 특화 소프트웨어
  *
    2. 이벤트 버스에 게시된 CDC
    3. CDC는 이벤트 버스에 게시되며 하나 이상의 분석 유스 케이스에서 사용할 수 있습니다. 버스의 이벤트는 내구성이 뛰어나며 오류가 발생한 경우 재생 가능합니다.
  *
    3. 이벤트 병합
    4. 각 이벤트(삽입, 삭제, 업데이트)는 대상 테이블에 적용됩니다. 최종 결과는 소스 테이블보다 짧은 지연 시간이 있는 테이블의 구체화 뷰. 대상 테이블에 해당하는 메타데이터는 새로 고침 타임스탬프와 기타 속성을 반영하기 위해 데이터 카탈로그에 업데이트됩니다.
* 특징
  * 일반적으로 서비스 초기에 데이터는 데이터 베이스에 저장됩니다.
  * 실시간 처리가 가능합니다.
  * 새벽마다 통계 및 분석 를 위한 대량 배치 작업을 줄일 수 있습니다.
  * 데이터 변경분만 전송되기에 훨씬 효율적이고 필요한 자원이 줄어듭니다.
* 강점
  * CDC 패턴은 소스 데이터스토어에 미치는 성능 영향을 최소화하면서 대상을 업데이트하는 지연 시간이 짧은 솔루션
  * CDC 어댑터는 광범위한 데이터스토어에 사용할 수 있습니다.
  * 데이터 이동 과정에서 필터링 또는 데이터 변환을 지원합니다.
  * 증분 수집(incremental ingestion)을 사용해 대형 테이블을 지원합니다.
* 약점
  * CDC 어댑터의 최적 구성 옵션을 선택하는 데 필요한 전문 지식이 없으면 온보딩이 쉽지 않습니다.
  * Hadoop MapReduce 대신 Spark를 사용하는 병합 구현에서는 약 10억 행 이상의 매우 큰 테이블에서 문제가 발생할 수 있습니다.
  * 증분 변경 내용을 추적하려면 CDC 열이 있는 테이블이 필요합니다.
  * 필터링 또는 데이터 변환을 제한적으로 지원합니다.
* CDC 솔루션
  * Maxwell , SpinalTap , Yelp의 MySQL Streamer 및 Debezium
* 아파치 Kafka와 결합된 Debezium
  * Debezium은 지연 시간이 짧은 CDC 어댑터
  * 데이터베이스 기술에 관계없이 표준화된 이벤트 모델에서 커밋된 데이터베이스 변경 사항을 캡처합니다.
  * 이벤트는 변경된 내용, 시기 및 위치를 설명합니다. 이벤트는 아파치 Kafka에 하나 이상의 Kafka 토픽(일반적으로 데이터베이스 테이블당 하나의 토픽)으로 게시됩니다.
  * Kafka는 모든 이벤트가 복제되고 완전히 정렬되도록 보장하며, 많은 소비자가 업스트림 시스템에 거의 영향을 주지 않으면서 동일한 데이터 변경 이벤트를 독립적으로 사용할 수 있게 합니다. 병합 프로세스 중에 오류가 발생하는 경우 중단된 지점에서 정확히 다시 시작할 수 있습니다.
  * 이벤트는 정확히 한 번(exactly-once) 또는 최소한 한 번(at-least-once) 정확하게 전달됩니다. 각 데이터베이스/테이블에 대한 모든 데이터 변경 이벤트는 업스트림 데이터베이스에서 발생한 것과 동일한 순서로 전달됩니다.
  * CDC 레코드를 구체화된 대상 테이블로 병합하기 위해 널리 사용되는 접근 방식은 MapReduce를 사용하는 일괄 처리 지향적 방식 또는 Spark와 같은 기술을 사용하는 스트리밍 지향적 방식
* DBLog
  * ![image](https://user-images.githubusercontent.com/47103479/223737000-fcd1db01-2b0f-4a30-ac86-c3dd9735cb04.png)
    * https://netflixtechblog.com/dblog-a-generic-change-data-capture-framework-69351fb9099b
  * 트랜잭션 로그는 일반적으로 제한적이므로 보유, 변경 내용의 전체 기록을 포함하지 않을 수 있습니다. 따라서 소스의 전체 상태를 캡처하려면 덤프가 필요
  * DBLog 기능
    * 캡처된 로그 이벤트를 순서대로 처리
    * 특정 테이블 또는 테이블의 특정 기본 키에 대해 모든 테이블에서 언제든지 덤프를 수행
    * 청크로 덤프를 가져옴으로써 로그를 덤프 이벤트와 인터리브
    * 테이블에 대한 잠금은 획득되지 않으므로 원본 데이터베이스의 쓰기 트래픽에 영향을 미치지 않음
    * 출력이 스트림, 데이터 저장소 또는 API가 될 수 있도록 모든 종류의 출력을 지원
    * 고가용성을 염두에 두고 설계되었음
  * 데이터 동기화 및 이벤트 처리 사용 사례의 경우 실시간으로 변경 사항을 캡처하는 기능을 넘어 다음 요구 사항을 충족
    * 전체 상태를 캡처
    * 언제든지 수리를 시작합니다. 덤프를 일회성 설정 활동으로 처리하는 대신 모든 테이블, 특정 테이블 또는 특정 기본 키에 대해 언제든지 활성화하는 것을 목표로 합니다. 이는 데이터가 손실되거나 손상된 경우 다운스트림을 복구하는 데 중요합니다.
    * 실시간 이벤트에 대한 고가용성을 제공
    * 데이터베이스 영향 최소화
    * 모든 출력에 이벤트 쓰기. 스트리밍 기술의 경우 Netflix는 Kafka, SQS, Kinesis 및 Keystone과 같은 Netflix 전용 스트리밍 솔루션과 같은 다양한 옵션을 활용
    * 관계형 데이터베이스 지원

## Reference

* https://www.oreilly.com/library/view/the-self-service-data/9781492075240/
* https://www.oreilly.com/library/view/data-pipelines-pocket/9781492087823/
* https://arxiv.org/abs/2010.12597
