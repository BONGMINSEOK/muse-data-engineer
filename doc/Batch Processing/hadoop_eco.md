# hadoop eco system 
- ![image](https://user-images.githubusercontent.com/47103479/235437110-33e0b5cd-75b0-49d0-8d98-90c5b786607f.png)
  - https://www.oreilly.com/library/view/apache-hive-essentials/9781788995092/e846ea02-6894-45c9-983a-03875076bb5b.xhtml

## Data Ingestion
- [Flume](https://flume.apache.org/)
  - 플룸은 많은 양의 로그 데이터를 효율적으로 수집, 취합, 이동하기 위한 분산형 소프트웨어로 클라우데라에서 개발한 서버 로그 수집 도구 입니다. 각 서버에 에이전트가 설치 되고, 에이전트로부터 데이터를 전달 받는 콜렉터로 구성됩니다.
  - 플룸은 이벤트 기반의 대용량 데이터를 하둡으로 수집하기 위해 개발되었으며 다수의 웹 서버에서 로그파일을 수집하고 해당 파일의 로그 이벤트를 처리하기 위해 HDFS에 위치한 새로운 통합 파일로 옮기는 것은 플룸을 사용하는 전형적인 예입니다.
  - Flume은 기본적으로 웹 서버에서 생성된 대량의 로그 파일을 Hadoop으로 빠르고 안정적으로 스트리밍할 수 있도록 설계됐으며, Kafka 브로커, 페이스북, 트위터와 같은 소스의 데이터를 포함해 이벤트 데이터를 처리하도록 진화했습니다.
- [Kafka](https://kafka.apache.org/)
  - 카프카는 링크드인에서 개발한 여러 대의 분산 서버에서 대량의 데이터를 처리하는 분산 메시징 시스템입니다. 대용량 실시간 로그 처리에 특화 되어 있으며 메시지를 받고, 받은 메시지를 다른 시스템이나 장치에 보내기 위해 사용합니다. 
  - 기본적으로 도착한 메시지를 큐에 저장하고, 순차적으로 메시지를 소비하는 Pub/Sub 패턴을 가지는 메시지 브로커
  - 발행(publish) - 구독(subscribe) 모델로 구성되어 메시징, 메트릭 수집, 로그 수집, 스트림 처리 등 다양한 용도로 사용합니다.
- [Sqoop](https://sqoop.apache.org/)
  - 일반적으로 관계형 데이터베이스와 파일 시스템 간에 HDFS와 아파치 Hive로 대량의 데이터를 이동할 때 사용됩니다.즉, 구조화된 데이터 저장소(관계형 데이터베이스)와 하둡 간의 효율적인 데이터 전송.
  - 관계형 데이터 베이스와 아파치 하둡간의 대용량 데이터들을 효율적으로 변환 하여 주는 명령 줄 인터페이스 애플리케이션. 클라이언트-서버모델로 구현됩니다.
  - RDBMS와 HDFS간 대용량 데이터 전송을 위한 솔루션입니다. HDFS, RDBMS, DW, NoSQL 등 다양한 저장소에 대용량 데이터를 신속하게 전송할 수 있는 방법을 제공합니다. 상용RDBMS도 지원하고, MySQL, PostgreSQL 오픈소스 RDBMS도 지원합니다.
  - 클라이언트는 소스 및 대상 데이터스토어에 설치되고 데이터 이동은 클라이언트와 대응하는 Sqoop 서버에 의해 MapReduce 작업으로 오케스트레이션됩니다.
- [Nifi](https://nifi.apache.org/)
  - 소프트웨어 시스템 간 데이터 흐름을 자동화하도록 설계된 소프트웨어 프로젝트로 미국 국가안보국(NSA)에서 개발한 시스템 간 데이터 전달을 효율적으로 처리, 관리, 모니터링하기 위한 최적의 시스템입니다.
  - 데이터 변환을 설계, 제어, 모니터링하기 위한 풍부한 웹 기반 GUI를 제공합니다. NiFi는 기본적으로 소스(추출함수), 프로세서(변환 함수), 싱크(로드 함수)라는 세 가지 유형으로 구분된 250개 이상의 표준화된 함수를 제공하며 프로세서 기능의 예로는 데이터 향상, 검증, 필터링, 결합, 분할, 조정이 있습니다.
  - 파이썬, 셸, Spark에는 부가적인 프로세서를 추가할 수 있습니다. 프로세서는 데이터 처리에서 매우 동시적으로 구현되며, 병렬 프로그래밍의 고유한 복잡성을 사용자에게 숨깁니다. 프로세서는 동시에 실행되며 로드에 대처하기 위해 여러 스레드에 걸쳐 있습니다.
  - 외부 소스에서 데이터를 가져오면 NiFi 데이터 흐름 내부의 FlowFile로 표시됩니다. FlowFile은 기본적으로 관련 메타 정보가 있는 원본 데이터에 대한 포인터
  - 프로세서의 세 가지 출력
    - 실패 : FlowFIle을 올바르게 처리할 수 없는 경우, 원본 FlowFIle이 출력으로 라우팅됨
    - 원본 : 들어오는 FlowFile이 처리되면 원본 FlowFile이 출력으로 라우팅됨
    - 성공 : 성공적으로 처리된 FlowFile은 이 관계로 라우팅됨
- [Fluentd](https://www.fluentd.org/)
  - 로그 수집 미들웨어로 저장 장소가 분산되어 있는 데이터와 로그의 수집을 간단하고 스마트하게 해결해 줌으로써 데이터로부터 가치를 창출하기 위한 비용을 최소화 할 수 있습니다.
  - 크로스 플랫폼 오픈 소스 데이터 수집 소프트웨어 프로젝트로 트레저 데이터에서 개발한 로그 수집시스템입니다. 주로 루비와 C로 작성되었습니다. 여러 형태의 로그를 전달받아서 원하는 저장소에 쌓을수 있습니다. 비정형, 반정형 데이터를 필터링, 버퍼링하여 사용자가 지정하는 데이터베이스나 클라우드 저장소에 효율적으로 저장할 수 있습니다.
  - 기본적인 구조는 Flume NG와 비슷합니다. Flume의 Source, Channel, Sink가 Input, Buffer, Output으로 대체되었습니다. 장점은 각 파트 별로 플러그인을 만들기 쉽습니다.

## Stream Processing
- [Flink](https://flink.apache.org/)
  - 스트림 및 일괄 처리 기능을 갖춘 오픈 소스 스트림 처리 프레임워크입니다.
  - 특징 
    - Dataflow 모델을 기반으로 DataStream API에서 이벤트 시간 및 비순차적 처리 지원
    - 매우 높은 처리량과 낮은 이벤트 대기 시간을 동시에 지원하는 런타임
    - 인 메모리 및 코어 외부 데이터 처리 알고리즘 간의 효율적이고 강력한 전환을 위한 맞춤형 메모리 관리
- [Beam](https://beam.apache.org/)
  - 일괄 처리 및 스트리밍 데이터 병렬 처리 파이프라인을 정의하기 위한 오픈소스 통합 모델 
  - 데이터 사용자는 오픈소스 Beam SDK 중 하나를 사용해 파이프라인을 정의하는 프로그램을 구축합니다.
  - 파이프라인은 Beam이 지원하는 분산 처리 백엔드 중 하나에 의해 실행되며 아파치 Apex, 아파치 Flink, 아파치 Spark, 구글 Cloud Dataflow가 포함됩니다.
- [Storm](https://storm.apache.org/)
  - YARN에서도 Twitter의 스트림 처리를 위한 프레임워크입니다.
  - 셀프서비스 스트리밍 데이터 패턴의 예이며, 일괄 처리를 스트림 처리의 하위 집합으로 취급합니다.
  - 빠른 처리가 장점입니다.
- [Samza](https://samza.apache.org/)
  - Apache Samza는 LinkedIn에서 만든 오픈 소스 프로젝트로 Kafka 및 YARN을 기반으로 하는 스트림 처리 프레임워크입니다.
  - Samza는 여러 Kafka 주제에서 메트릭을 스트리밍할 수 있으며 Hadoop YARN에 배포할 수 있습니다.
  - Disk 활용 대량 처리가 가능합니다.    
