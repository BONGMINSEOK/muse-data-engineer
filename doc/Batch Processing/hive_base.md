# Hive 
- 하둡 기반의 데이터 웨어하우징 프레임워크로, 빠른 속도로 성장하는 페이스북의 소셜 네트워크에서 매일같이 생산되는 대량의 데이터를 관리하고 학습하기 위해 개발되었습니다.
- 하이브에서 레코드 단위 갱신(record-level update), 삽입, 삭제를 할 수 없긴 하지만 쿼리로 새 테이블을 만들 수 있고 쿼리 결과를 파일로 남길 수도 있습니다.
- SQL은 비즈니스 인텔리전스 분야의 도구에서 사용되는 공통 언어(lingua franca)이기 때문에(예를 들어 ODBC는 공통 인터페이스) 해당 분야의 상용 제품과 쉽게 통합할 수 있습니다.
- Hive는 데이터양에 좌우되지 않는 쿼리 엔진으로 다음과 같은 특징이 있습니다.
  - 높은 확장성과 내결함성을 목표로 설계되었습니다.
  - 대규모 배치 처리를 꾸준히 실행합니다.
  - 텍스트 데이터를 가공하거나 열 지향 스토리지를 만드는 등의 무거운 처리는 아무래도 처리 시간이 길어지는 경향이 있어서 Hive에서 실행하는것이 적합합니다.
  - 분산시스템의 동향은 서서히 인 메모리의 데이터 처리로 옮겨 가고 있지만, Hive는 앞으로도 데이터양에 좌우되지 않는 쿼리 엔진으로 계속 이용될 것입니다.
- 한계
    - Hive는 온라인 트랜잭션 처리(OLTP)용으로 설계되지 않았으며 온라인 분석 처리에만 사용됩니다.
    - Hive는 데이터 덮어쓰기 또는 파악을 지원하지만 업데이트 및 삭제는 지원하지 않습니다.
    - Hive에서는 하위 쿼리가 지원되지 않습니다.
- 로깅
  - 하이브의 에러 로그는 로컬 파일시스템의 ${java.io.tmpdir}/${user.name}/hive.log에서 찾을 수 있음, 환경 설정 문제나 다른 유형의 에러를 진단할 때 매우 유용합니다. 
  - 로깅 설정 파일은 conf/hive-log4j.properties고, 로그 수준과 다른 로깅 관련 설정을 변경하고 싶으면 이 파일을 변경하면 됩니다. 

## 읽기 스키마와 쓰기 스키마의 비교 
- ![image](https://user-images.githubusercontent.com/47103479/216994378-e8b79276-d2b6-4313-9b3b-d44e88a93b24.png)
  - https://www.oreilly.com/content/hadoop-what-you-need-to-know/
- 쓰기 스키마(schema on write) - 전통적인 데이터베이스에서 테이블의 스키마는 데이터를 로드하는 시점에 검증됩니다. 로드 중인 데이터가 스키마에 부합되지 않으면 해당 데이터를 거부합니다. 데이버테이스 쓰는 시점에 떼이터의 스키마를 검증하기 때문입니다.
- 읽기 스키마(schema on read) - 하이브는 로드 시점이 아니라 쿼리를 실행할 때 그 데이터를 검증합니다.
- 두 방식은 서로 상충 관계(trade-off)로 읽기 스키마는 데이터베이스 내부 형식으로 데이터를 읽거나 파싱하거나 디스크에 직렬화할 필요가 없기 때문에 초기에 매우 빠른 속도로 데이터를 로드할 수 있습니다. 로드 조작을 위해서는 단순히 파일을 복사하거나 이동하기만 하면 됩니다.
- 쓰기 스키마는 데이터베이스가 컬럼 단위의 데이터 색인과 압축을 제공하기 때문에 더 빠르게 쿼리를 수행할 수 있음, 상대적으로 데이터베이스에 데이터를 로드하는 시간은 더 오래 걸림, 더욱이 쿼리가 정해지지 않아서 로드 시점에 스키마를 지정할 수 없고 색인도 적용할 수 없는 경우도 빈번합니다. 

## HiveQL : 쿼리
- SELECT ... FROM 절
  - SQL에서 SELECT 프로젝션(projection) 연산자. FROM 절은 레코드를 선택하기 위해 필요한 테이블. 뷰 또는 중첩 쿼리(nested query)를 식별합니다.
  - 컬렉션 데이터형의 컬럼을 선택하면 하이브는 출력을 위해 JSON(Java Script Object Notation)문법을 사용합니다.
  - ARRAY 데이터형은 쉼표로 구분된 목록이 [...]로 둘려싸여 있습니다.
  - MAP의 경우 쉼표로 구분된 키:값 쌍의 목록을 {...}로 둘러싸는 JSON 표현을 사용합니다.
  - STRUCT로 JSON 맵 형식을 사용합니다.
 - 하이브는 오버 플로우나 언더플로우가 발생할 때 더 넓은 범위의 데이터형이 존재하더라도 결과를 자동으로 변환하지 않는 자바 데이터형 규칙을 따름니다. 
- 기타 내장 함수
  - ```sql
  - > parse_url(url,partname,key) : HOST, PATH, QUERY, REF,PROTOCOL, AUTHORITY, FILE, USERINFO, QUERY:<key>. 옵션 키는 마지막에 QUERY:<key>를 요청함 
  - > find_in_set(s, 쉼표로 구분된 String) : 쉼표로 구분된 문자열에서 s의 색인을 반환함. 찾지 못하면 NULL이 반환됨
  - > locate(substr,str,pos) : str의 post 위치로부터 substr이 있는 색인을 반환함 
  - > instr(str,substr) : str에서 substr의 색인을 반환함
  - > str_to_map(s,delim1,delim2) : delim1을 키-값 쌍의 구분자로 사용하고 delim2를 키와 값의 구분자로 사용하여 문자열 s를 파싱한 후 맵을 생성함 
  - > sentences(s,lang,locale) : 문자열 s를 단어의 배열로 이루어진 문장의 배열로 반환함 
  - > ngrams(array<array<string>>, N, K, pf) : 텍스트에서 top-K n-gram을 반환함. pf는 정밀도
  - > context_ngrams(array<array<string>>,array<string>, int K, int pf> : ngrams와 같지만 출력 배열에서 두 번째 단어 배열로 시작하는 n-gram을 찾음
  - > in_file(s, filename) : filenmae 파일에서 문자열 s가 나타나면 true를 반환함 
